

const axios = require("axios");
const { cmd } = require("../command");

cmd({
    pattern: "gpt",
    alias: "ai",
    desc: "Interact with ChatGPT using the Dreaded API.",
    category: "ai",
    react: "ü§ñ",
    use: "<your query>",
    filename: __filename,
}, async (conn, mek, m, { from, args, q, reply }) => {
    try {
        // V√©rification de l'entr√©e utilisateur
        if (!q) return reply("*‚ö†Ô∏è Please provide a query for ChatGPT.*\n\n*Example:*\n*.gpt What is AI?*");

        // Utilisation de `${text}` dans le endpoint API
        const text = q;  // Texte de la requ√™te de l'utilisateur
        const encodedText = encodeURIComponent(text);  // S'assurer que le texte est encod√© correctement

        const url = `https://api.dreaded.site/api/chatgpt?text=${encodedText}`;

        console.log('Requesting URL:', url);  // Afficher l'URL pour v√©rifier

        // Appel √† l'API avec headers personnalis√©s (ajoute des headers si n√©cessaire)
        const response = await axios.get(url, {
            headers: {
                'User-Agent': 'Mozilla/5.0',  // Ajouter un User-Agent pour simuler une requ√™te valide
                'Accept': 'application/json',  // Sp√©cifier que l'on attend une r√©ponse JSON
            }
        });

        // D√©boguer et afficher la r√©ponse compl√®te
        console.log('Full API Response:', response.data);

        // V√©rification de la structure de la r√©ponse
        if (!response || !response.data || !response.data.result) {
            return reply("‚ùå No response received from the GPT API. Please try again later.");
        }

        // Extraire uniquement le texte de la r√©ponse (le prompt)
        const gptResponse = response.data.result.prompt;

        if (!gptResponse) {
            return reply("‚ùå The API returned an unexpected format. Please try again later.");
        }

        // Image AI √† envoyer
        const ALIVE_IMG = 'https://i.ibb.co/JjD7C5sj/4396ea90a1dcd020.jpg'; // Remplacez par l'URL de votre image AI

        // L√©gende avec des informations format√©es
        const formattedInfo = `*ü§ñ ·¥Ñ ú·¥Ä·¥õ.…¢·¥ò·¥õ  Ä·¥ás·¥ò·¥è…¥s·¥á:*\n\n${gptResponse}`;

        // Envoyer le message avec image et l√©gende
        await conn.sendMessage(from, {
            image: { url: ALIVE_IMG }, // Assurez-vous que l'URL est valide
            caption: formattedInfo,
            contextInfo: { 
                mentionedJid: [m.sender],
                forwardingScore: 999,
                isForwarded: true,
                forwardedNewsletterMessageInfo: {
                    newsletterJid: '120363318387454868@newsletter',
                    newsletterName: 'ùêÄ…≠ŒπÃáŒπÃá ùêå∆ä ùêÄùêà ü§ñ',
                    serverMessageId: 143
                }
            }
        }, { quoted: mek });

    } catch (error) {
        console.error("Error in GPT command:", error);

        // Affichage du message d'erreur dans la console pour plus de d√©tails
        if (error.response) {
            console.log("Error Response Data:", error.response.data);
        } else {
            console.log("Error Details:", error.message);
        }

        // R√©pondre avec des d√©tails de l'erreur
        const errorMessage = `
‚ùå An error occurred while processing the GPT command.
üõ† *Error Details*:
${error.message}

Please report this issue or try again later.
        `.trim();
        return reply(errorMessage);
    }
});
cmd({
    pattern: "llama3",
    desc: "Get a response from Llama3 AI using the provided prompt.",
    category: "ai",
    react: "ü§ñ",
    filename: __filename,
    use: ".llama3 <your prompt>"
}, async (conn, mek, m, { from, q, reply }) => {
    try {
        // Check if a prompt is provided by the user
        if (!q) return reply("‚ö†Ô∏è Please provide a prompt for Llama3 AI.");

        // Inform the user that the request is being processed
        await reply("> *Processing your prompt...*");

        // API URL with encoded user prompt
        const apiUrl = `https://api.davidcyriltech.my.id/ai/llama3?text=${encodeURIComponent(q)}`;

        // Send a GET request to the API
        const response = await axios.get(apiUrl);
        console.log("Llama3 API Response:", response.data);

        // Extract AI response
        let llamaResponse;
        if (typeof response.data === "string") {
            llamaResponse = response.data.trim();
        } else if (typeof response.data === "object") {
            llamaResponse = response.data.response || response.data.result || JSON.stringify(response.data);
        } else {
            llamaResponse = "Unable to process the AI response.";
        }

        // AI image to attach
        const AI_IMG = 'https://i.ibb.co/JjD7C5sj/4396ea90a1dcd020.jpg'; // Replace with a valid image URL

        // Formatted response text
        const formattedInfo = `*ü§ñ  ü ü·¥Ä·¥ç·¥Ä3  Ä·¥ás·¥ò·¥è…¥s·¥á:*\n\n${llamaResponse}`;

        // Send the response with an image
        await conn.sendMessage(from, {
            image: { url: AI_IMG }, // Ensure the URL is valid
            caption: formattedInfo,
            contextInfo: { 
                mentionedJid: [m.sender],
                forwardingScore: 999,
                isForwarded: true,
                forwardedNewsletterMessageInfo: {
                    newsletterJid: '120363318387454868@newsletter',
                    newsletterName: 'ùêÄ…≠ŒπÃáŒπÃá ùêå∆ä ùêÄùêà ü§ñ',
                    serverMessageId: 143
                }
            }
        }, { quoted: mek });

    } catch (error) {
        console.error("Error in llama3 command:", error);
        return reply(`‚ùå An error occurred: ${error.message}`);
    }
});
cmd({
    pattern: "openai",
    alias: ["chatgpt", "gpt3", "open-gpt"],
    desc: "Chat with OpenAI",
    category: "ai",
    react: "üß†",
    filename: __filename
},
async (conn, mek, m, { from, args, q, reply, react }) => {
    try {
        if (!q) return reply("Please provide a message for OpenAI.\nExample: `.openai Hello`");

        const apiUrl = `https://vapis.my.id/api/openai?q=${encodeURIComponent(q)}`;
        const { data } = await axios.get(apiUrl);

        if (!data || !data.result) {
            await react("‚ùå");
            return reply("OpenAI failed to respond. Please try again later.");
        }

        await reply(`üß† *OpenAI Response:*\n\n${data.result}`);
        await react("‚úÖ");
    } catch (e) {
        console.error("Error in OpenAI command:", e);
        await react("‚ùå");
        reply("An error occurred while communicating with OpenAI.");
    }
});

cmd({
    pattern: "deepseek",
    alias: ["deep", "seekai"],
    desc: "Chat with DeepSeek AI",
    category: "ai",
    react: "üß†",
    filename: __filename
},
async (conn, mek, m, { from, args, q, reply, react }) => {
    try {
        if (!q) return reply("Please provide a message for DeepSeek AI.\nExample: `.deepseek Hello`");

        const apiUrl = `https://api.ryzendesu.vip/api/ai/deepseek?text=${encodeURIComponent(q)}`;
        const { data } = await axios.get(apiUrl);

        if (!data || !data.answer) {
            await react("‚ùå");
            return reply("DeepSeek AI failed to respond. Please try again later.");
        }

        await reply(`üß† *DeepSeek AI Response:*\n\n${data.answer}`);
        await react("‚úÖ");
    } catch (e) {
        console.error("Error in DeepSeek AI command:", e);
        await react("‚ùå");
        reply("An error occurred while communicating with DeepSeek AI.");
    }
});
